{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 - Model Training: RandomForest and XGBoost\n",
    "\n",
    "**Objective:**\n",
    "1. Load the prepared data from the feature engineering stage.\n",
    "2. Split the data into training and testing sets.\n",
    "3. Train and evaluate two regression models: `RandomForestRegressor` and `XGBoostRegressor`.\n",
    "4. Predict the target variables: `Heating_Load` and `Cooling_Load`.\n",
    "5. Compare performance metrics (MAE, MSE, R²) to select the best models.\n",
    "6. Save the trained models for later use in predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Paths (Adjusted for the local environment) ---\n",
    "# The paths are relative to the 'notebooks/' directory\n",
    "PROCESSED_DATA_PATH = '../data/processed/energy_efficiency_prepared.csv'\n",
    "MODELS_DIR = '../models/'\n",
    "\n",
    "# Create the models directory if it doesn't exist\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading\n",
    "\n",
    "We load the dataset that was processed and prepared in the `1.3-feature-engineering.ipynb` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X3</th>\n",
       "      <th>X5</th>\n",
       "      <th>X7</th>\n",
       "      <th>Y1</th>\n",
       "      <th>Y2</th>\n",
       "      <th>X6_3</th>\n",
       "      <th>X6_4</th>\n",
       "      <th>X6_5</th>\n",
       "      <th>X8_1</th>\n",
       "      <th>X8_2</th>\n",
       "      <th>X8_3</th>\n",
       "      <th>X8_4</th>\n",
       "      <th>X8_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>21.33</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>21.33</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>21.33</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>21.33</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.84</td>\n",
       "      <td>28.28</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         X1        X3   X5   X7     Y1     Y2   X6_3   X6_4   X6_5   X8_1  \\\n",
       "0  1.000000  0.285714  1.0  0.0  15.55  21.33  False  False  False  False   \n",
       "1  1.000000  0.285714  1.0  0.0  15.55  21.33   True  False  False  False   \n",
       "2  1.000000  0.285714  1.0  0.0  15.55  21.33  False   True  False  False   \n",
       "3  1.000000  0.285714  1.0  0.0  15.55  21.33  False  False   True  False   \n",
       "4  0.777778  0.428571  1.0  0.0  20.84  28.28  False  False  False  False   \n",
       "\n",
       "    X8_2   X8_3   X8_4   X8_5  \n",
       "0  False  False  False  False  \n",
       "1  False  False  False  False  \n",
       "2  False  False  False  False  \n",
       "3  False  False  False  False  \n",
       "4  False  False  False  False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_csv(PROCESSED_DATA_PATH)\n",
    "    print(\"Data loaded successfully:\")\n",
    "    display(df.head())\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at the path '{PROCESSED_DATA_PATH}'.\")\n",
    "    print(\"Make sure you have run the previous notebooks to generate the processed data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preparation for Modeling\n",
    "\n",
    "We separate the features (X) from the target variables (y). We will train a model for each target: `Heating_Load` and `Cooling_Load`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = ['X1','X3','X5','X7','X6_3','X6_4','X6_5','X8_1','X8_2','X8_3','X8_4','X8_5']\n",
    "\n",
    "TARGET_HEATING = 'Y1' # Heating_Load\n",
    "TARGET_COOLING = 'Y2' # Cooling_Load\n",
    "\n",
    "X = df[FEATURES]\n",
    "y_heating = df[TARGET_HEATING]\n",
    "y_cooling = df[TARGET_COOLING]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model for `Heating_Load`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_h, X_test_h, y_train_h, y_test_h = train_test_split(X, y_heating, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RandomForest Results for Heating Load ---\n",
      "MAE: 0.6349\n",
      "MSE: 4.2722\n",
      "R²: 0.9580\n"
     ]
    }
   ],
   "source": [
    "rf_model_h = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_model_h.fit(X_train_h, y_train_h)\n",
    "y_pred_rf_h = rf_model_h.predict(X_test_h)\n",
    "\n",
    "print(\"--- RandomForest Results for Heating Load ---\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test_h, y_pred_rf_h):.4f}\")\n",
    "print(f\"MSE: {mean_squared_error(y_test_h, y_pred_rf_h):.4f}\")\n",
    "print(f\"R²: {r2_score(y_test_h, y_pred_rf_h):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. XGBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- XGBoost Results for Heating Load ---\n",
      "MAE: 0.6846\n",
      "MSE: 4.3036\n",
      "R²: 0.9577\n"
     ]
    }
   ],
   "source": [
    "xgb_model_h = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, random_state=42, n_jobs=-1)\n",
    "xgb_model_h.fit(X_train_h, y_train_h)\n",
    "y_pred_xgb_h = xgb_model_h.predict(X_test_h)\n",
    "\n",
    "print(\"--- XGBoost Results for Heating Load ---\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test_h, y_pred_xgb_h):.4f}\")\n",
    "print(f\"MSE: {mean_squared_error(y_test_h, y_pred_xgb_h):.4f}\")\n",
    "print(f\"R²: {r2_score(y_test_h, y_pred_xgb_h):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model for `Cooling_Load`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(X, y_cooling, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RandomForest Results for Cooling Load ---\n",
      "MAE: 1.4548\n",
      "MSE: 8.4917\n",
      "R²: 0.9023\n"
     ]
    }
   ],
   "source": [
    "rf_model_c = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_model_c.fit(X_train_c, y_train_c)\n",
    "y_pred_rf_c = rf_model_c.predict(X_test_c)\n",
    "\n",
    "print(\"--- RandomForest Results for Cooling Load ---\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test_c, y_pred_rf_c):.4f}\")\n",
    "print(f\"MSE: {mean_squared_error(y_test_c, y_pred_rf_c):.4f}\")\n",
    "print(f\"R²: {r2_score(y_test_c, y_pred_rf_c):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. XGBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- XGBoost Results for Cooling Load ---\n",
      "MAE: 1.1549\n",
      "MSE: 7.2045\n",
      "R²: 0.9171\n"
     ]
    }
   ],
   "source": [
    "xgb_model_c = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, random_state=42, n_jobs=-1)\n",
    "xgb_model_c.fit(X_train_c, y_train_c)\n",
    "y_pred_xgb_c = xgb_model_c.predict(X_test_c)\n",
    "\n",
    "print(\"--- XGBoost Results for Cooling Load ---\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test_c, y_pred_xgb_c):.4f}\")\n",
    "print(f\"MSE: {mean_squared_error(y_test_c, y_pred_xgb_c):.4f}\")\n",
    "print(f\"R²: {r2_score(y_test_c, y_pred_xgb_c):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Saving\n",
    "\n",
    "Based on the results, the XGBoost model shows slightly superior performance. Therefore, we will save the two XGBoost models in the `models/` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for Heating Load saved at: ../models/xgb_heating_load_model.joblib\n",
      "Model for Cooling Load saved at: ../models/xgb_cooling_load_model.joblib\n"
     ]
    }
   ],
   "source": [
    "heating_model_path = os.path.join(MODELS_DIR, 'xgb_heating_load_model.joblib')\n",
    "cooling_model_path = os.path.join(MODELS_DIR, 'xgb_cooling_load_model.joblib')\n",
    "\n",
    "joblib.dump(xgb_model_h, heating_model_path)\n",
    "joblib.dump(xgb_model_c, cooling_model_path)\n",
    "\n",
    "print(f\"Model for Heating Load saved at: {heating_model_path}\")\n",
    "print(f\"Model for Cooling Load saved at: {cooling_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusion\n",
    "\n",
    "In this notebook, we have successfully trained and evaluated the RandomForest and XGBoost models.\n",
    "\n",
    "The **XGBoost** model proved to be the slightly best performer for both tasks. The winning models have been saved and are ready to be used in the next steps of the MLOps cycle."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
