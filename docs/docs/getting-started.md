Getting started
===============


### ğŸ§© Repository Structure

```bash
project/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/              â† Original noisy dataset
â”‚   â”œâ”€â”€ interim/          â† Intermediate datasets (drop / fill NaN versions)
â”‚   â””â”€â”€ processed/        â† Final cleaned datasets ready for modeling
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_EDA_and_Cleaning.ipynb
â”‚   â”œâ”€â”€ 02_EDA_Clean_Fill.ipynb
â”‚   â””â”€â”€ 03_EDA_Clean_Drop.ipynb
â”‚
â””â”€â”€ dvc.yaml              â† DVC tracking file
```

---

### âš™ï¸ Environment Setup

To ensure reproducibility, install all dependencies from the provided `requirements.txt` file.  
This will automatically install the correct versions of all required libraries.

```bash
# Create and activate a virtual environment (recommended)
python -m venv venv
source venv/bin/activate  # (Linux/Mac)
venv\Scripts\activate     # (Windows)

# Install dependencies
pip install -r requirements.txt
```
â¸»

### ğŸ“¦ Data Access

The dataset is versioned using DVC (Data Version Control).
To pull the latest versions of all datasets (raw, interim, processed):

```bash
dvc pull
```

You can also retrieve specific files if needed:
```bash
dvc pull data/raw/energy_noisy.csv
dvc pull data/interim/energy_drop.csv
dvc pull data/interim/energy_fill.csv
```

â¸»

### ğŸš€ How to Run
* Notebooks version
1. Start with the main notebook:
   - EDA_and_Cleaning.ipynb â†’ Performs raw dataset exploration, null analysis, and creates two branches (drop vs fill).
2. Continue with:
   - EDA_Clean_Fill.ipynb â†’ Applies outlier detection and full cleaning to the Fill-NaN version.
   - 03_EDA_Clean_Drop.ipynb â†’ Applies outlier detection and full cleaning to the Drop-NaN version.
3. All results are automatically saved and versioned via DVC under data/processed/.

* Python script version
â¸»