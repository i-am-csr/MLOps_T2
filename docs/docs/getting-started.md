Getting started
===============


### ğŸ§© Repository Structure

```bash
project/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/              â† Original noisy dataset
â”‚   â”œâ”€â”€ interim/          â† Intermediate datasets (drop / fill NaN versions)
â”‚   â””â”€â”€ processed/        â† Final cleaned datasets ready for modeling
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_EDA_and_Cleaning.ipynb
â”‚   â”œâ”€â”€ 02_EDA_Clean_Fill.ipynb
â”‚   â””â”€â”€ 03_EDA_Clean_Drop.ipynb
â”‚
â””â”€â”€ dvc.yaml              â† DVC tracking file
```

---

### âš™ï¸ Environment Setup

To ensure reproducibility, use [uv](https://github.com/astral-sh/uv), a fast Python package manager and resolver. uv can automatically create and activate your virtual environment, install dependencies, and synchronize your environment with the lock file.

```bash
# Create and activate a virtual environment using uv
uv venv

# Install dependencies and synchronize with lock file
uv pip sync
```

If you need to add a new package, use:
```bash
uv pip install <package-name>
```
This will automatically update requirements.txt and uv.lock.

If you want to upgrade all dependencies to their latest compatible versions:
```bash
uv pip compile --upgrade
uv pip sync
```

For more details, see the [uv documentation](https://github.com/astral-sh/uv).

---

### ğŸ“¦ Data Access

The dataset is versioned using DVC (Data Version Control).
To pull the latest versions of all datasets (raw, interim, processed):

```bash
dvc pull
```

You can also retrieve specific files if needed:
```bash
dvc pull data/raw/energy_noisy.csv
dvc pull data/interim/energy_drop.csv
dvc pull data/interim/energy_fill.csv
```

â¸»

### ğŸš€ How to Run
* Notebooks version
1. Start with the main notebook:
   - EDA_and_Cleaning.ipynb â†’ Performs raw dataset exploration, null analysis, and creates two branches (drop vs fill).
2. Continue with:
   - EDA_Clean_Fill.ipynb â†’ Applies outlier detection and full cleaning to the Fill-NaN version.
   - 03_EDA_Clean_Drop.ipynb â†’ Applies outlier detection and full cleaning to the Drop-NaN version.
3. All results are automatically saved and versioned via DVC under data/processed/.

* Python script version
